# Estado Real: Python SDK + Cerebelum Core

**Fecha:** 2024-12-11
**Hallazgo:** El Python SDK NO estÃ¡ usando el Engine actualmente

---

## âœ… Lo que SÃ tienen implementado

### 1. Engine System (Elixir Workflows) - COMPLETO

```elixir
defmodule MyWorkflow do
  use Cerebelum.Workflow

  workflow do
    timeline do
      step1() |> step2() |> step3()
    end
  end

  def step1(context), do: {:ok, :data}
end

# EjecuciÃ³n
Cerebelum.execute_workflow(MyWorkflow, inputs)
```

**Capacidades:**
- âœ… Execution.Engine (GenStateMachine)
- âœ… EventStore con persistencia PostgreSQL
- âœ… StateReconstructor - reconstruye estado desde eventos
- âœ… Resurrection completa - workflows sobreviven restarts
- âœ… Sleep multi-dÃ­a con hibernaciÃ³n
- âœ… Approval workflows
- âœ… WorkflowScheduler - despierta workflows automÃ¡ticamente
- âœ… Registry - mapea execution_id â†’ PID
- âœ… Supervisor OTP - restart policies

---

### 2. Python SDK (DSL Declarativo) - COMPLETO

```python
from cerebelum import step, workflow

@step
async def fetch_user(context, inputs):
    user_id = inputs["user_id"]
    user = await db.get_user(user_id)
    return {"ok": user}

@step
async def send_email(context, fetch_user):
    user = fetch_user["ok"]
    await email.send(user["email"])
    return {"ok": "sent"}

@workflow
def my_workflow(wf):
    wf.timeline(fetch_user >> send_email)

# EjecuciÃ³n local
result = await my_workflow.execute({"user_id": 123})
```

**Capacidades:**
- âœ… @step decorator con dependency resolution
- âœ… @workflow decorator con timeline/diverge/branch DSL
- âœ… DSLLocalExecutor - ejecuta localmente en Python
- âœ… Worker class - registra con Core via gRPC
- âœ… Blueprint serialization a protobuf
- âœ… DistributedExecutor - submit workflows a Core
- âœ… Async helpers: poll(), retry(), sleep()

---

### 3. Worker System (DistribuciÃ³n) - COMPLETO

**En Core (Elixir):**
- âœ… BlueprintRegistry - guarda blueprints de workflows
- âœ… TaskRouter - queue tasks, long-polling, sticky routing
- âœ… ExecutionStateManager - tracking de steps completados (ETS)
- âœ… WorkerRegistry - workers activos
- âœ… worker_service_server.ex - gRPC endpoints

**En Python:**
- âœ… Worker polls for tasks
- âœ… Worker ejecuta steps
- âœ… Worker devuelve resultados

---

## âŒ Lo que NO estÃ¡ conectado

### El Gap CrÃ­tico

```
Python Worker â†’ gRPC ExecuteRequest
                  â†“
           worker_service_server.ex:execute_workflow() (lÃ­nea 369)
                  â†“
           BlueprintRegistry.get_blueprint()
                  â†“
           âŒ ExecutionStateManager.create_execution() [ETS only!]
           âŒ TaskRouter.queue_initial_tasks()
                  â†“
           âŒ NO llama a Execution.Supervisor.start_execution()
           âŒ NO usa el Engine
           âŒ NO emite eventos
           âŒ NO hay resurrection
```

### Consecuencias

**Workflows de Python NO tienen:**
- âŒ EventStore (solo ETS en memoria)
- âŒ Resurrection automÃ¡tica
- âŒ Sleep multi-dÃ­a con hibernaciÃ³n
- âŒ StateReconstructor
- âŒ WorkflowScheduler
- âŒ Sobrevivir restarts del Core

**Si el Core se reinicia:**
- âŒ ExecutionStateManager se pierde (ETS)
- âŒ TaskRouter state se pierde
- âŒ Ejecuciones de Python workflows se pierden

---

## ğŸ¯ Lo que pensabas que tenÃ­an

> "mi idea fue crear todo el sistema para funcionar con elixir, y no perder lo de OTP, entonces el python SDK, estaba sobre eso, entonces teniamos todas esas ventajas tmb con python"

**La intenciÃ³n era correcta**, pero la implementaciÃ³n estÃ¡ incompleta:

### Arquitectura Deseada (NO implementada)

```
Python Worker â†’ gRPC ExecuteRequest
                  â†“
           worker_service_server.ex:execute_workflow()
                  â†“
           âœ… Execution.Supervisor.start_execution()  â† FALTA ESTO
                  â†“
           âœ… Execution.Engine (GenStateMachine)
                  â†“
           Para cada step:
             - Engine emite StepStartedEvent
             - Engine delega a TaskRouter
             - Worker ejecuta step
             - Worker devuelve resultado
             - Engine emite StepCompletedEvent
             - Engine continÃºa
                  â†“
           Sleep/Approval:
             - Worker envÃ­a SleepRequest
             - Engine procesa {:sleep, [...], data}
             - Engine emite SleepStartedEvent
             - Hibernation funciona
             - Resurrection funciona âœ…
```

---

## ğŸ“Š ComparaciÃ³n Real

| Feature | Elixir Workflows | Python SDK (HOY) | Python SDK (IDEAL) |
|---------|-----------------|------------------|-------------------|
| Engine execution | âœ… | âŒ | âœ… |
| EventStore | âœ… | âŒ | âœ… |
| Resurrection | âœ… | âŒ | âœ… |
| Sleep multi-dÃ­a | âœ… | âŒ | âœ… |
| Hibernation | âœ… | âŒ | âœ… |
| OTP Supervisor | âœ… | âŒ | âœ… |
| StateReconstructor | âœ… | âŒ | âœ… |
| WorkflowScheduler | âœ… | âŒ | âœ… |
| Distributed workers | N/A | âœ… | âœ… |
| Python DSL | N/A | âœ… | âœ… |

---

## ğŸ”§ QuÃ© falta implementar

### 1. Modificar `worker_service_server.ex:execute_workflow`

**Antes (lÃ­neas 369-412):**
```elixir
def execute_workflow(request, _stream) do
  # ...
  case BlueprintRegistry.get_blueprint(request.workflow_module) do
    {:ok, blueprint} ->
      # âŒ Esto NO usa el Engine
      {:ok, _exec_state} = ExecutionStateManager.create_execution(...)
      {:ok, _task_ids} = TaskRouter.queue_initial_tasks(...)
  end
end
```

**DespuÃ©s (PROPUESTA):**
```elixir
def execute_workflow(request, _stream) do
  inputs = struct_to_map(request.inputs)

  case BlueprintRegistry.get_blueprint(request.workflow_module) do
    {:ok, blueprint} ->
      # âœ… Usar el Engine
      {:ok, pid} = Execution.Supervisor.start_execution(
        Cerebelum.WorkflowDelegatingWorkflow,
        inputs,
        blueprint: blueprint,
        workflow_module: request.workflow_module
      )

      # El Engine maneja todo: eventos, sleep, resurrection
  end
end
```

### 2. Crear `Cerebelum.WorkflowDelegatingWorkflow`

```elixir
defmodule Cerebelum.WorkflowDelegatingWorkflow do
  use Cerebelum.Workflow

  @doc """
  Workflow dinÃ¡mico que carga blueprint de Python y delega steps a workers.
  """

  workflow do
    # Timeline se carga dinÃ¡micamente del blueprint
  end

  # Cada step delega al Worker via TaskRouter
  def execute_step(context, step_name, inputs) do
    task = %{
      workflow_module: context.workflow_module,
      step_name: step_name,
      inputs: inputs
    }

    {:ok, task_id} = TaskRouter.queue_task(context.execution_id, task)

    # Esperar resultado del worker
    result = await_task_completion(task_id, timeout: 300_000)

    # Procesar respuesta del worker
    case result do
      {:sleep, duration_ms, data} ->
        # Worker pidiÃ³ sleep - Engine lo maneja
        {:sleep, [milliseconds: duration_ms], data}

      {:approval, approval_data} ->
        # Worker pidiÃ³ approval - Engine lo maneja
        {:approval, approval_data}

      {:ok, data} ->
        {:ok, data}

      {:error, reason} ->
        {:error, reason}
    end
  end

  defp await_task_completion(task_id, opts) do
    # Implementar blocking wait para resultado del worker
    # Opciones:
    # 1. GenServer.call con timeout
    # 2. Process mailbox con receive
    # 3. Registry + monitor
  end
end
```

### 3. Extender `TaskResult` protobuf

```protobuf
message TaskResult {
  string task_id = 1;
  string execution_id = 2;
  string worker_id = 3;

  TaskStatus status = 4;
  google.protobuf.Struct result = 5;
  ErrorInfo error = 6;

  // âœ… NUEVO: Sleep/Approval support
  SleepRequest sleep_request = 7;
  ApprovalRequest approval_request = 8;
}

message SleepRequest {
  int64 duration_ms = 1;
  google.protobuf.Struct data = 2;
}

message ApprovalRequest {
  string approval_type = 1;
  google.protobuf.Struct data = 2;
  int64 timeout_ms = 3;
}

enum TaskStatus {
  TASK_STATUS_UNSPECIFIED = 0;
  SUCCESS = 1;
  FAILED = 2;
  TIMEOUT = 3;
  CANCELLED = 4;
  SLEEP = 5;      // âœ… NUEVO
  APPROVAL = 6;   // âœ… NUEVO
}
```

### 4. Actualizar Python SDK `sleep()`

```python
async def sleep(duration: int) -> None:
    """Sleep workflow-aware."""
    context = get_current_context()

    if context.distributed:
        # âœ… Return marker para que worker envÃ­e SleepRequest
        return {"_sleep": True, "duration_ms": duration}
    else:
        # Local mode
        await asyncio.sleep(duration / 1000)
```

### 5. Actualizar `Worker._execute_task`

```python
async def _execute_task(self, task) -> TaskResult:
    # Ejecutar step
    output = await step_function(ctx, **inputs)

    # âœ… NUEVO: Detectar sleep marker
    if isinstance(output, dict) and output.get("_sleep"):
        return TaskResult(
            task_id=task.task_id,
            execution_id=task.execution_id,
            worker_id=self.worker_id,
            status=TaskStatus.SLEEP,
            sleep_request=SleepRequest(
                duration_ms=output["duration_ms"],
                data=struct_from_dict(output.get("data", {}))
            )
        )

    # âœ… NUEVO: Detectar approval marker
    if isinstance(output, dict) and output.get("_approval"):
        return TaskResult(
            ...
            status=TaskStatus.APPROVAL,
            approval_request=ApprovalRequest(...)
        )

    # Normal success
    return TaskResult(
        ...
        status=TaskStatus.SUCCESS,
        result=struct_from_dict(output)
    )
```

### 6. Actualizar `worker_service_server.ex:submit_result`

```elixir
def submit_result(result, _stream) do
  case result.status do
    :SLEEP ->
      # Notificar al Engine que el step estÃ¡ sleeping
      # Engine procesa y entra en :sleeping state
      notify_engine_sleep(result)

    :APPROVAL ->
      # Notificar al Engine que espera approval
      notify_engine_approval(result)

    :SUCCESS ->
      # Normal flow
      notify_engine_success(result)
  end
end
```

---

## ğŸ¯ Resultado Final

### DespuÃ©s de implementar esto:

```python
# Python Worker code
@step
async def wait_for_deployment(context, inputs):
    # âœ… Este sleep funcionarÃ¡ con resurrection
    await sleep(timedelta(days=1))
    return {"ok": "deployed"}

@workflow
def my_workflow(wf):
    wf.timeline(deploy >> wait_for_deployment >> verify)

# Execute
await my_workflow.execute(inputs, distributed=True)
```

**Lo que pasarÃ¡:**
1. Python worker ejecuta `deploy` step
2. Python worker ejecuta `wait_for_deployment`
3. Worker detecta `sleep(1 day)` y envÃ­a `SleepRequest`
4. Core/Engine recibe y procesa como `{:sleep, [milliseconds: 86400000], data}`
5. Engine emite `SleepStartedEvent`
6. Engine puede hibernar el proceso (libera memoria)
7. **Core se reinicia** â†’ âœ… Workflow sobrevive
8. WorkflowScheduler despierta el workflow despuÃ©s de 1 dÃ­a
9. Engine continÃºa con `verify` step
10. Worker ejecuta `verify`
11. Workflow completa âœ…

---

## ğŸ“‹ Tasks de ImplementaciÃ³n

1. [ ] Crear `WorkflowDelegatingWorkflow` module
2. [ ] Implementar `await_task_completion` con blocking wait
3. [ ] Modificar `execute_workflow` para usar `Execution.Supervisor`
4. [ ] Extender protobuf con `SleepRequest`/`ApprovalRequest`
5. [ ] Regenerar protobuf: `mix protobuf.generate`
6. [ ] Actualizar Python `sleep()` helper
7. [ ] Actualizar `Worker._execute_task` para detectar markers
8. [ ] Actualizar `submit_result` para notificar Engine
9. [ ] Testing end-to-end: Python â†’ Sleep â†’ Kill Core â†’ Resurrect â†’ Complete
10. [ ] DocumentaciÃ³n

---

## ğŸ’¡ Ventajas vs Temporal.io

Una vez implementado, tendrÃ¡n:

| Feature | Temporal.io | Cerebelum (despuÃ©s de implementar) |
|---------|-------------|-------------------------------------|
| Resurrection | âœ… | âœ… |
| Sleep multi-dÃ­a | âœ… | âœ… |
| Event sourcing | âœ… | âœ… |
| OTP/BEAM power | âŒ | âœ… (Ãºnico!) |
| Python DSL | â­â­â­ | â­â­â­â­â­ (mÃ¡s simple) |
| Replay determinÃ­stico | âœ… Complejo | âŒ Pero no lo necesitan! |
| Distributed workers | âœ… | âœ… |

**Ventaja competitiva:** NO necesitan replay determinÃ­stico porque el Engine mantiene el estado. MÃ¡s simple que Temporal pero con los mismos beneficios de resurrection.
