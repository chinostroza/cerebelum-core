# Re: Best practices para polling/waiting en steps

**From:** Cerebelum Team
**To:** Development Team
**Date:** December 11, 2024
**Subject:** Long-running operations support - New SDK helpers

---

Â¡Hola equipo!

Gracias por la excelente pregunta sobre polling y waiting patterns. Nos da mucho gusto que estÃ©s usando Cerebelum para workflows de deployment automÃ¡tico! ğŸš€

Tenemos **muy buenas noticias**: acabamos de lanzar **helpers oficiales** en el SDK (v2.1.0) especÃ­ficamente para este caso de uso. Tu approach actual funciona, pero ahora tenemos formas mÃ¡s idiomÃ¡ticas y poderosas de manejarlo.

---

## âœ¨ Nuevos Helpers Disponibles (SDK v2.1.0)

Hemos agregado al SDK:

```python
from cerebelum import sleep, poll, retry, ProgressReporter
```

### 1ï¸âƒ£ `poll()` - Para operaciones con latencia variable

**Tu caso de uso (Digital Ocean droplet):**

```python
from cerebelum import step, poll, Context

@step
async def create_droplet(context: Context, inputs: dict) -> dict:
    # Crear droplet
    droplet = digitalocean.Droplet(...)
    droplet.create()

    return {"droplet_id": droplet.id}

@step
async def wait_for_droplet_ip(context: Context, create_droplet: dict) -> dict:
    droplet_id = create_droplet["droplet_id"]

    # âœ… APPROACH RECOMENDADO - Usar poll()
    result = await poll(
        check_fn=lambda: manager.get_droplet(droplet_id),
        interval=5000,  # Check every 5 seconds
        max_attempts=30,  # Max 2.5 minutes
        success_condition=lambda d: d.ip_address is not None,
        on_attempt=lambda n, d: print(f"Waiting for IP... ({n}/30)")
    )

    return {"ip_address": result.ip_address}
```

**Ventajas sobre el approach manual:**

âœ… **MÃ¡s limpio** - Separa lÃ³gica de polling de lÃ³gica de negocio
âœ… **Reusable** - Misma funciÃ³n para todos tus casos de polling
âœ… **Flexible** - `success_condition` customizable
âœ… **Timeouts** - Soporte para `max_attempts` y `timeout` total
âœ… **Progress reporting** - Callback `on_attempt` para logs
âœ… **Future-ready** - Cuando uses Core distribuido, se integra con workflow resurrection

---

### 2ï¸âƒ£ `retry()` - Para failures transitorios

**Tu pregunta sobre retry automÃ¡tico:**

```python
from cerebelum import step, retry, Context

@step
async def connect_server(context: Context, wait_for_droplet_ip: dict) -> dict:
    ip = wait_for_droplet_ip["ip_address"]

    # âœ… RETRY CON EXPONENTIAL BACKOFF
    connection = await retry(
        fn=establish_ssh_connection,
        ip=ip,
        max_attempts=10,
        delay=5000,  # Start with 5s
        backoff=2.0,  # Double each time (5s, 10s, 20s, 40s...)
        on_error=SSHConnectionError,  # Only retry SSH errors
        on_attempt=lambda n, e: print(f"SSH retry {n}/10: {e}")
    )

    return {"connection": connection}

# Helper function
async def establish_ssh_connection(ip: str):
    """Connect via SSH - may fail transiently."""
    client = paramiko.SSHClient()
    client.connect(ip, username="root", timeout=10)
    return client
```

**Features:**

âœ… **Exponential backoff** - Configurable con parÃ¡metro `backoff`
âœ… **Selective retry** - Solo reintenta errores especÃ­ficos con `on_error`
âœ… **Progress callbacks** - Tracking de cada intento
âœ… **Async/sync support** - Funciona con ambos tipos de funciones

---

### 3ï¸âƒ£ `ProgressReporter` - Para reportar progreso

**Tu pregunta sobre `context.update_progress()`:**

```python
from cerebelum import step, ProgressReporter, Context, sleep

@step
async def long_deployment(context: Context, inputs: dict) -> dict:
    progress = ProgressReporter(context)

    progress.update(0, "Creating infrastructure...")
    await provision_infrastructure()

    progress.update(33, "Deploying application...")
    await deploy_app()

    progress.update(66, "Running migrations...")
    await run_migrations()

    progress.update(100, "Deployment complete!")

    return {"status": "deployed"}
```

**Output en consola:**

```
  [long_deployment] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 33% - Deploying application...
```

**Futuro (con cerebelum-web):**

Cuando implementemos la UI web, estos progress updates se mostrarÃ¡n en tiempo real en el dashboard! ğŸ“Š

---

### 4ï¸âƒ£ `sleep()` - Para workflows de larga duraciÃ³n

**Tu pregunta sobre pausar workflows:**

```python
from cerebelum import step, sleep, Context
from datetime import timedelta

@step
async def send_reminder(context: Context, inputs: dict) -> dict:
    user_email = inputs["user_email"]

    # Send first reminder
    send_email(user_email, "Welcome!")

    # Sleep for 24 hours
    await sleep(timedelta(days=1))  # â­ Workflow-aware sleep

    # Send second reminder (continues after 24h)
    send_email(user_email, "Day 1 reminder")

    return {"reminders_sent": 2}
```

**Importante para tu use case:**

- **En modo local** (DSLLocalExecutor): Usa `asyncio.sleep()` normal
- **En modo distribuido** (con Core): El workflow puede **hibernar** y **resucitar**
  - Proceso se termina para ahorrar memoria
  - Estado se persiste en DB
  - Scheduler automÃ¡tico lo despierta despuÃ©s de 24h
  - ContinÃºa exactamente donde quedÃ³ âœ¨

**Esto significa:**

âœ… Workflows pueden "dormir" dÃ­as/semanas
âœ… Sobreviven a restarts del sistema
âœ… Aprobaciones humanas que tardan dÃ­as funcionan perfecto
âœ… Deployments de 10-20 minutos son triviales

---

## ğŸ”„ RefactorizaciÃ³n Recomendada

### Antes (tu approach actual):

```python
@step
async def create_droplet(context: Context, inputs: dict) -> dict:
    droplet.create()

    # âŒ Polling manual en el step
    max_attempts = 30
    attempt = 0
    while attempt < max_attempts:
        droplet.load()
        if droplet.ip_address:
            break
        print(f"Esperando IP... ({attempt + 1}/{max_attempts})")
        time.sleep(5)
        attempt += 1

    if not droplet.ip_address:
        raise RuntimeError("Timeout esperando IP")

    return {"ip_address": droplet.ip_address}
```

### DespuÃ©s (approach recomendado):

```python
@step
async def create_droplet(context: Context, inputs: dict) -> dict:
    """Create droplet - returns immediately."""
    droplet.create()
    return {"droplet_id": droplet.id}

@step
async def wait_for_droplet_ip(context: Context, create_droplet: dict) -> dict:
    """Wait for IP using poll() helper - CLEAN & REUSABLE."""
    droplet_id = create_droplet["droplet_id"]

    # âœ… Limpio, declarativo, reusable
    result = await poll(
        check_fn=lambda: manager.get_droplet(droplet_id),
        interval=5000,
        max_attempts=30,
        success_condition=lambda d: d.ip_address is not None,
        on_attempt=lambda n, _: print(f"Waiting for IP... ({n}/30)")
    )

    return {"ip_address": result.ip_address}

@workflow
def droplet_deployment(wf):
    wf.timeline(create_droplet >> wait_for_droplet_ip >> configure_server)
```

**Por quÃ© separar en steps?**

âœ… **ComposiciÃ³n** - Reutilizar `wait_for_droplet_ip` en otros workflows
âœ… **Testing** - Testear creaciÃ³n y waiting independientemente
âœ… **Observabilidad** - Ver duraciÃ³n de cada fase separadamente
âœ… **Determinismo** - Event sourcing captura cada transiciÃ³n
âœ… **Debugging** - Replay desde cualquier punto

---

## ğŸ“š Otros Casos de Uso

### SSL Certificate (Let's Encrypt):

```python
@step
async def wait_for_ssl_cert(context: Context, request_cert: dict) -> dict:
    domain = request_cert["domain"]

    result = await poll(
        check_fn=lambda: check_cert_status(domain),
        interval=10000,  # Every 10 seconds
        timeout=timedelta(minutes=5),  # Max 5 minutes total
        success_condition=lambda r: r["status"] == "issued"
    )

    return result
```

### PostgreSQL Ready:

```python
@step
async def wait_for_postgres(context: Context, create_db: dict) -> dict:
    db_url = create_db["connection_string"]

    result = await poll(
        check_fn=lambda: test_db_connection(db_url),
        interval=2000,  # Every 2 seconds
        max_attempts=30,
        success_condition=lambda r: r.get("connectable") is True
    )

    return {"db_ready": True}
```

### CI/CD Build Complete:

```python
@step
async def wait_for_build(context: Context, trigger_build: dict) -> dict:
    build_id = trigger_build["build_id"]

    result = await poll(
        check_fn=lambda: get_build_status(build_id),
        interval=30000,  # Every 30 seconds
        max_attempts=60,  # Max 30 minutes
        success_condition=lambda b: b["status"] in ["success", "failure"],
        on_attempt=lambda n, b: print(f"Build status: {b['status']}")
    )

    if result["status"] == "failure":
        raise RuntimeError(f"Build failed: {result['error']}")

    return result
```

---

## ğŸ¯ Ejemplo Completo

Hemos creado un ejemplo completo con todos los patterns:

**Ver:** `examples/python-sdk/08_long_running_workflows.py`

Incluye:
- âœ… Digital Ocean droplet deployment (tu use case)
- âœ… SSL certificate issuance
- âœ… Multi-day workflows con sleep
- âœ… Deployment completo con progress reporting
- âœ… Retry logic con exponential backoff

**Ejecutar:**

```bash
cd examples/python-sdk
python3 08_long_running_workflows.py
```

---

## ğŸš€ Roadmap Futuro

### Actualmente (SDK v2.1.0):

âœ… `poll()`, `retry()`, `sleep()`, `ProgressReporter` funcionan en **modo local**
âœ… Workflows corren completamente en tu proceso Python
âœ… Ideal para desarrollo y workflows cortos (<1 hora)

### PrÃ³ximamente (cuando uses Core distribuido):

Cuando conectes al Core de Elixir (opcional):

âœ… **Workflow Resurrection** - Sobrevive a restarts del sistema
âœ… **Process Hibernation** - Workflows largos liberan memoria automÃ¡ticamente
âœ… **Distributed Execution** - Workers en mÃºltiples mÃ¡quinas
âœ… **Web UI** - Dashboard en tiempo real (cerebelum-web)
âœ… **Observability** - MÃ©tricas de Prometheus (cerebelum-observability)

**Tu cÃ³digo NO cambia** - Los helpers funcionan en ambos modos! ğŸ‰

---

## ğŸ“– DocumentaciÃ³n Completa

### API Reference:

```python
async def poll(
    check_fn: Callable,
    *,
    interval: int = 5000,  # ms between checks
    max_attempts: int = 30,
    timeout: Optional[Union[int, timedelta]] = None,
    success_condition: Optional[Callable[[Any], bool]] = None,
    on_attempt: Optional[Callable[[int, Any], None]] = None
) -> Any
```

```python
async def retry(
    fn: Callable,
    *args,
    max_attempts: int = 3,
    delay: int = 1000,  # ms
    backoff: float = 1.0,
    on_error: Optional[type[Exception]] = None,
    on_attempt: Optional[Callable[[int, Optional[Exception]], None]] = None,
    **kwargs
) -> Any
```

```python
async def sleep(duration: Union[int, float, timedelta]) -> None
# int/float: milliseconds
# timedelta: time delta object
```

---

## ğŸ¤” Preguntas Respondidas

> **1. Â¿Es este el approach recomendado?**

Tu approach funciona correctamente, pero ahora recomendamos usar `poll()` por:
- MÃ¡s limpio y declarativo
- Reusable across workflows
- Future-ready para resurrection
- Mejor separaciÃ³n de concerns

> **2. Retry mechanism: Â¿El SDK tiene soporte para retry automÃ¡tico?**

âœ… **SÃ­!** Usa la funciÃ³n `retry()`:

```python
result = await retry(
    fn=connect_server,
    max_attempts=10,
    delay=5000,
    on_error=SSHConnectionError
)
```

> **3. Progress reporting: Â¿Hay alguna forma de reportar progreso sin `print()`?**

âœ… **SÃ­!** Usa `ProgressReporter`:

```python
progress = ProgressReporter(context)
progress.update(50, "Halfway done...")
```

Actualmente imprime a stdout, pero cuando uses cerebelum-web se mostrarÃ¡ en UI!

> **4. Pausar y reanudar workflows de 10-20 minutos**

âœ… **SÃ­!** Usa `sleep()`:

```python
await sleep(timedelta(minutes=15))
```

En modo local: async sleep normal
En modo distribuido: workflow resurrection automÃ¡tico

---

## ğŸ’¡ Best Practices

### 1. Separar steps para polling

```python
# âœ… GOOD - Separado en steps
create_resource >> wait_for_resource >> configure_resource

# âŒ AVOID - Todo en un step
create_and_wait_resource >> configure_resource
```

### 2. Usar success_condition especÃ­fica

```python
# âœ… GOOD - CondiciÃ³n especÃ­fica
success_condition=lambda d: d.ip_address is not None

# âŒ AVOID - CondiciÃ³n vaga
success_condition=lambda d: d  # Cualquier truthy value
```

### 3. Timeout razonable

```python
# âœ… GOOD - Timeout total + max attempts
poll(
    check_fn=...,
    interval=5000,
    max_attempts=30,  # 2.5 minutes
    timeout=timedelta(minutes=3)  # Backup timeout
)
```

### 4. Progress callbacks informativos

```python
# âœ… GOOD - Progreso Ãºtil
on_attempt=lambda n, r: print(f"Attempt {n}: status={r['status']}")

# âŒ AVOID - Sin informaciÃ³n
on_attempt=lambda n, r: print(f"Attempt {n}")
```

---

## ğŸ‰ ConclusiÃ³n

**Tu approach actual funciona perfectamente**, pero con estos nuevos helpers puedes:

âœ… CÃ³digo mÃ¡s limpio y mantenible
âœ… Reutilizar lÃ³gica de polling/retry
âœ… Better separation of concerns
âœ… Progress reporting built-in
âœ… Future-ready para cuando uses Core distribuido

**Update recomendado:**

```bash
# Actualizar SDK
cd examples/python-sdk
git pull origin main

# Tu cÃ³digo actual sigue funcionando
# Pero ahora puedes usar los helpers!
```

**Â¿Preguntas o dudas?**

No dudes en preguntar! Estamos muy activos y nos encanta el feedback. ğŸš€

**Links Ãºtiles:**

- ğŸ“˜ Ejemplo completo: `examples/python-sdk/08_long_running_workflows.py`
- ğŸ“– Docs: `docs/async-operations-guide.md`
- ğŸ’¬ GitHub Discussions: [cerebelum-io/cerebelum-core/discussions](https://github.com/cerebelum-io/cerebelum-core/discussions)

---

Gracias por usar Cerebelum! ğŸ§ âœ¨

**Equipo Cerebelum**
c@zea.cl
